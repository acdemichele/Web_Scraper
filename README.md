# Web Crawler CLI Application
This Node.js CLI application is a web crawler that analyzes the internal linking profile of any website provided as a command-line argument. It was developed using Test-Driven Development (TDD) with Jest.

### Installation
Before running the application, ensure you have Node.js installed on your system. You can download and install it from Node.js official website.

Clone this repository to your local machine:


```git clone https://github.com/your-username/web-crawler.git```

Navigate to the project directory:

```cd web-crawler```

Install dependencies:

```npm install```

### Usage

To use the web crawler CLI, run the following command from the terminal:


```node crawler.js <website-url>```

Replace <website-url> with the URL of the website you want to crawl. For example:


```node crawler.js https://example.com```

### Features

- Crawls the provided website to analyze its internal linking profile.
- Provides a report on the internal linking profile of the website.
- Developed using Test-Driven Development (TDD) with Jest for robustness and reliability.


### Test
To run tests, use the following command:

```npm test```

This will execute all the tests written using Jest to ensure the correctness of the application.

### Contributing
Contributions are welcome! If you find any issues or have suggestions for improvements, please feel free to open an issue or submit a pull request.

### License
This project is licensed under the MIT License - see the LICENSE file for details.

